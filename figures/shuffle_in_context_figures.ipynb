{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shuffled In-Context Video Clips Evaluation Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "shots = [2, 4, 8, 12, 16]\n",
    "metrics = [\"STS-CE\", \"STS-BE\", \"RougeL\", \"BLEU\"]\n",
    "\n",
    "\n",
    "def draw_graphs(models, fig_name):\n",
    "    # Plotting\n",
    "    fig, axes = plt.subplots(\n",
    "        len(metrics), 1, figsize=(24, 8 * len(metrics)), sharex=True\n",
    "    )\n",
    "\n",
    "    # Iterate through each metric to create a subplot\n",
    "    lines = []\n",
    "    for i, metric in enumerate(metrics):\n",
    "        ax = axes[i]\n",
    "        ax.tick_params(axis=\"both\", which=\"major\", labelsize=28)\n",
    "        ax.axhline(0, color=\"black\", linewidth=6, linestyle=\"--\")\n",
    "        for model_name, data in models.items():\n",
    "            (line,) = ax.plot(\n",
    "                data[\"meta\"][\"shots\"],\n",
    "                data[metric][: len(data[\"meta\"][\"shots\"])],\n",
    "                label=f\"{model_name}\",\n",
    "                linestyle=data[\"meta\"][\"linestyle\"],\n",
    "                linewidth=8,\n",
    "                marker=\"D\",\n",
    "                markersize=16,\n",
    "            )\n",
    "            lines.append(line)\n",
    "        ax.set_ylabel(metric, fontsize=32, fontweight=\"bold\")\n",
    "        ax.set_ylim(-0.035, 0.035)\n",
    "        ax.set_xticks(shots)\n",
    "        ax.set_xlim(min(shots), max(shots))\n",
    "        ax.grid(True)\n",
    "\n",
    "    fig.legend(\n",
    "        lines, models, loc=\"lower center\", bbox_to_anchor=(0.5, 1), fontsize=32, ncols=1\n",
    "    )\n",
    "    fig.text(0.5, 0.0, \"Shots\", ha=\"center\", va=\"top\", fontsize=32, fontweight=\"bold\")\n",
    "\n",
    "    # Adjust layout to prevent overlap\n",
    "    plt.tight_layout()\n",
    "    # bbox_inches=\"tight\" ensures that all the visible content\n",
    "    # is saved into the pdf file.\n",
    "    plt.savefig(fig_name, bbox_inches=\"tight\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffle In-Context Video Clips (Vanilla BLIP-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "shuffled_blip_2_opt_27b = {\n",
    "    \"STS-CE\": np.array([0.4004, 0.429, 0.4535, 0.4438, 0.3765]),\n",
    "    \"STS-BE\": np.array([0.486, 0.5202, 0.546, 0.541, 0.4715]),\n",
    "    # 'BERTScore-F1': np.array([-0.8172, 0.3585, 0.5949, 0.5467, -0.3248]),\n",
    "    \"RougeL\": np.array([0.4626, 0.4966, 0.5135, 0.4975, 0.4221]),\n",
    "    \"BLEU\": np.array([0.1607, 0.1738, 0.1819, 0.1695, 0.1141]),\n",
    "}\n",
    "blip_2_opt_27b = {\n",
    "    \"STS-CE\": np.array([0.4012, 0.432, 0.4575, 0.4469, 0.3809]),\n",
    "    \"STS-BE\": np.array([0.4862, 0.5222, 0.5486, 0.5422, 0.4755]),\n",
    "    # 'BERTScore-F1': np.array([-0.9048, 0.3596, 0.5919, 0.5613, -0.315]),\n",
    "    \"RougeL\": np.array([0.4612, 0.5006, 0.5204, 0.5019, 0.4271]),\n",
    "    \"BLEU\": np.array([0.1639, 0.1828, 0.1926, 0.1766, 0.1203]),\n",
    "}\n",
    "diff_blip_2_opt_27b = {\n",
    "    metric: shuffled_blip_2_opt_27b[metric] - blip_2_opt_27b[metric]\n",
    "    for metric in shuffled_blip_2_opt_27b.keys()\n",
    "}\n",
    "diff_blip_2_opt_27b[\"meta\"] = {\"shots\": shots, \"linestyle\": \"-\"}\n",
    "\n",
    "shuffled_blip_2_flan_t5_xl = {\n",
    "    \"STS-CE\": np.array([0.4303, 0.4506, 0.4723, 0.4825, 0.489]),\n",
    "    \"STS-BE\": np.array([0.4829, 0.5013, 0.5315, 0.549, 0.5586]),\n",
    "    # 'BERTScore-F1': np.array([0.5803, 0.5819, 0.5787, 0.5745, 0.5724]),\n",
    "    \"RougeL\": np.array([0.4335, 0.4453, 0.472, 0.489, 0.4985]),\n",
    "    \"BLEU\": np.array([0.123, 0.1309, 0.1644, 0.1874, 0.1966]),\n",
    "}\n",
    "blip_2_flan_t5_xl = {\n",
    "    \"STS-CE\": np.array([0.4371, 0.4532, 0.476, 0.4812, 0.5006]),\n",
    "    \"STS-BE\": np.array([0.4877, 0.502, 0.5315, 0.545, 0.5681]),\n",
    "    # 'BERTScore-F1': np.array([0.5802, 0.5833, 0.5829, 0.5792, 0.5765]),\n",
    "    \"RougeL\": np.array([0.4291, 0.4403, 0.4684, 0.4846, 0.5056]),\n",
    "    \"BLEU\": np.array([0.1188, 0.1258, 0.1609, 0.1771, 0.2052]),\n",
    "}\n",
    "diff_blip_2_flan_t5_xl = {\n",
    "    metric: shuffled_blip_2_flan_t5_xl[metric] - blip_2_flan_t5_xl[metric]\n",
    "    for metric in shuffled_blip_2_flan_t5_xl.keys()\n",
    "}\n",
    "diff_blip_2_flan_t5_xl[\"meta\"] = {\"shots\": shots, \"linestyle\": \"-\"}\n",
    "\n",
    "models = {\n",
    "    \"BLIP-2 OPT-2.7B (Shuffled - Control)\": diff_blip_2_opt_27b,\n",
    "    \"BLIP-2 Flan-T5-xl (Shuffled - Control)\": diff_blip_2_flan_t5_xl,\n",
    "}\n",
    "\n",
    "draw_graphs(models, \"vanilla-blip2-shuffle-in-context.pdf\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffle In-Context Video Clips (EILEV BLIP-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_eilev_blip_2_opt_27b = {\n",
    "    \"STS-CE\": np.array([0.46, 0.5263, 0.5916, 0.6178, 0.6294]),\n",
    "    \"STS-BE\": np.array([0.5483, 0.6042, 0.6572, 0.6776, 0.6879]),\n",
    "    # 'BERTScore-F1': np.array([0.6377, 0.6442, 0.6531, 0.6538, 0.6529]),\n",
    "    \"RougeL\": np.array([0.5328, 0.5702, 0.6034, 0.6198, 0.6264]),\n",
    "    \"BLEU\": np.array([0.2012, 0.24, 0.2689, 0.2904, 0.301]),\n",
    "}\n",
    "eilev_blip_2_opt_27b = {\n",
    "    \"STS-CE\": np.array([0.4897, 0.5569, 0.612, 0.6312, 0.6363]),\n",
    "    \"STS-BE\": np.array([0.571, 0.6284, 0.6735, 0.6898, 0.6936]),\n",
    "    # 'BERTScore-F1': np.array([0.6399, 0.6463, 0.6543, 0.6539, 0.6529]),\n",
    "    \"RougeL\": np.array([0.5396, 0.5785, 0.6102, 0.6249, 0.6296]),\n",
    "    \"BLEU\": np.array([0.2015, 0.2443, 0.2741, 0.2968, 0.3049]),\n",
    "}\n",
    "diff_eilev_blip_2_opt_27b = {\n",
    "    metric: shuffled_eilev_blip_2_opt_27b[metric] - eilev_blip_2_opt_27b[metric]\n",
    "    for metric in shuffled_eilev_blip_2_opt_27b.keys()\n",
    "}\n",
    "diff_eilev_blip_2_opt_27b[\"meta\"] = {\"shots\": shots, \"linestyle\": \"-\"}\n",
    "\n",
    "shuffled_eilev_blip_2_flan_t5_xl = {\n",
    "    \"STS-CE\": np.array([0.4978, 0.5404, 0.598, 0.6188, 0.6272]),\n",
    "    \"STS-BE\": np.array([0.5682, 0.6052, 0.6613, 0.6817, 0.6893]),\n",
    "    # 'BERTScore-F1': np.array([0.6419, 0.6494, 0.6538, 0.6579, 0.6594]),\n",
    "    \"RougeL\": np.array([0.5353, 0.5674, 0.6058, 0.6188, 0.6223]),\n",
    "    \"BLEU\": np.array([0.2148, 0.2452, 0.2831, 0.2892, 0.2877]),\n",
    "}\n",
    "eilev_blip_2_flan_t5_xl = {\n",
    "    \"STS-CE\": np.array([0.5176, 0.5539, 0.6089, 0.6276, 0.6349]),\n",
    "    \"STS-BE\": np.array([0.5812, 0.613, 0.6689, 0.6886, 0.6948]),\n",
    "    # 'BERTScore-F1': np.array([0.6394, 0.6477, 0.6527, 0.6561, 0.6572]),\n",
    "    \"RougeL\": np.array([0.5322, 0.5648, 0.607, 0.6203, 0.623]),\n",
    "    \"BLEU\": np.array([0.1992, 0.2373, 0.2834, 0.2931, 0.2913]),\n",
    "}\n",
    "diff_eilev_blip_2_flan_t5_xl = {\n",
    "    metric: shuffled_eilev_blip_2_flan_t5_xl[metric] - eilev_blip_2_flan_t5_xl[metric]\n",
    "    for metric in shuffled_eilev_blip_2_flan_t5_xl.keys()\n",
    "}\n",
    "diff_eilev_blip_2_flan_t5_xl[\"meta\"] = {\"shots\": shots, \"linestyle\": \"-\"}\n",
    "\n",
    "models = {\n",
    "    \"EILEV BLIP-2 OPT-2.7B (Shuffled - Control)\": diff_eilev_blip_2_opt_27b,\n",
    "    \"EILEV BLIP-2 Flan-T5-xl (Shuffled - Control)\": diff_eilev_blip_2_flan_t5_xl,\n",
    "}\n",
    "\n",
    "draw_graphs(models, \"eilev-blip2-shuffle-in-context.pdf\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "video-blip-KO49OV_G-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
