{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Data Exploration"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First load `fho_main.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"../../../ego4d/v2/annotations/fho_main.json\") as f:\n",
    "    fho_main = json.load(f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many structured verbs are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "from video_blip.data.ego4d import filter_action\n",
    "\n",
    "struct_verb_counter = Counter()\n",
    "freeform_verb_counter = Counter()\n",
    "no_critical_frames_frames = []\n",
    "critical_frames_no_frames = []\n",
    "non_other_struct_and_freeform_verb = 0\n",
    "for video in fho_main[\"videos\"]:\n",
    "    for interval in video[\"annotated_intervals\"]:\n",
    "        for action in interval[\"narrated_actions\"]:\n",
    "            if action[\"critical_frames\"] is None and action[\"frames\"] is not None:\n",
    "                no_critical_frames_frames.append(action)\n",
    "            elif action[\"critical_frames\"] is not None and action[\"frames\"] is None:\n",
    "                critical_frames_no_frames.append(action)\n",
    "            if filter_action(action):\n",
    "                if action[\"structured_verb\"] == \"[other]\":\n",
    "                    freeform_verb_counter[action[\"freeform_verb\"].strip().lower()] += 1\n",
    "                elif action[\"freeform_verb\"] is not None:\n",
    "                    non_other_struct_and_freeform_verb += 1\n",
    "                struct_verb_counter[action[\"structured_verb\"]] += 1\n",
    "\n",
    "print(f\"len(no_critical_frames_frames) = {len(no_critical_frames_frames)}\")\n",
    "print(f\"len(critical_frames_no_frames) = {len(critical_frames_no_frames)}\")\n",
    "print(f\"len(struct_verb_counter) = {len(struct_verb_counter)}\")\n",
    "print(f\"len(freeform_verb_counter) = {len(freeform_verb_counter)}\")\n",
    "print(f\"non_other_struct_and_freeform_verb = {non_other_struct_and_freeform_verb}\")\n",
    "print(\"=====structured verbs=========\")\n",
    "for verb, count in struct_verb_counter.items():\n",
    "    print(f\"{verb}: {count}\")\n",
    "print(\"=====freeform verbs=========\")\n",
    "for verb, count in freeform_verb_counter.items():\n",
    "    print(f\"{verb}: {count}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many structured nouns are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct_noun_counter = Counter()\n",
    "freeform_noun_counter = Counter()\n",
    "none_struct_and_freeform_noun = 0\n",
    "for video in fho_main[\"videos\"]:\n",
    "    for interval in video[\"annotated_intervals\"]:\n",
    "        for action in interval[\"narrated_actions\"]:\n",
    "            if not filter_action(action):\n",
    "                continue\n",
    "            if action[\"frames\"] is None:\n",
    "                continue\n",
    "            for frame in action[\"frames\"]:\n",
    "                if frame[\"frame_type\"] != \"pnr_frame\":\n",
    "                    # some actions don't have contact frames so use pnr_frame\n",
    "                    continue\n",
    "                for box in frame[\"boxes\"]:\n",
    "                    if box[\"object_type\"] != \"object_of_change\":\n",
    "                        continue\n",
    "                    if box[\"structured_noun\"] is None:\n",
    "                        if box[\"freeform_noun\"] is not None:\n",
    "                            freeform_noun_counter[\n",
    "                                box[\"freeform_noun\"].strip().lower()\n",
    "                            ] += 1\n",
    "                        else:\n",
    "                            none_struct_and_freeform_noun += 1\n",
    "                    struct_noun_counter[box[\"structured_noun\"]] += 1\n",
    "\n",
    "print(f\"len(struct_noun_counter) = {len(struct_noun_counter)}\")\n",
    "print(f\"len(freeform_noun_counter) = {len(freeform_noun_counter)}\")\n",
    "print(f\"none_struct_and_freeform_noun = {none_struct_and_freeform_noun}\")\n",
    "print(\"=====structured nouns=========\")\n",
    "for noun, count in struct_noun_counter.items():\n",
    "    print(f\"{noun}: {count}\")\n",
    "print(\"=====freeform nouns=========\")\n",
    "for noun, count in freeform_noun_counter.items():\n",
    "    print(f\"{noun}: {count}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about in `fho_lta_taxonomy.json`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../../ego4d/v2/annotations/fho_lta_taxonomy.json\") as f:\n",
    "    fho_lta_taxonomy = json.load(f)\n",
    "\n",
    "taxonomy_verbs = set(fho_lta_taxonomy[\"verbs\"])\n",
    "taxonomy_nouns = set(fho_lta_taxonomy[\"nouns\"])\n",
    "\n",
    "print(f\"len(taxonomy_verbs): {len(taxonomy_verbs)}\")\n",
    "print(f\"len(taxonomy_nouns): {len(taxonomy_nouns)}\")\n",
    "\n",
    "print(\n",
    "    \"taxonomy_verbs - struct_verb_counter.keys(): \"\n",
    "    f\"{taxonomy_verbs - struct_verb_counter.keys()}\"\n",
    ")\n",
    "print(\n",
    "    \"struct_verb_counter.keys() - taxonomy_verbs: \"\n",
    "    f\"{struct_verb_counter.keys() - taxonomy_verbs}\"\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"taxonomy_nouns - struct_noun_counter.keys(): \"\n",
    "    f\"{taxonomy_nouns - struct_noun_counter.keys()}\"\n",
    ")\n",
    "print(\n",
    "    \"struct_noun_counter.keys() - taxonomy_nouns: \"\n",
    "    f\"{struct_noun_counter.keys() - taxonomy_nouns}\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's flatten structured verbs and nouns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "pattern = re.compile(r\"^(.+)_\\((.+)\\)$\")\n",
    "\n",
    "\n",
    "def extract_words(s):\n",
    "    m = pattern.match(s)\n",
    "    if m is None:\n",
    "        extracted_words = [s]\n",
    "    else:\n",
    "        extracted_words = [m.group(1)] + m.group(2).split(\",_\")\n",
    "    words = []\n",
    "    for extracted in extracted_words:\n",
    "        words.extend(\n",
    "            word.replace(\"-\", \" \").replace(\"_\", \" \") for word in extracted.split(\"/\")\n",
    "        )\n",
    "    return words\n",
    "\n",
    "\n",
    "flat_verbs = set()\n",
    "for verb in taxonomy_verbs:\n",
    "    flat_verbs.update(extract_words(verb))\n",
    "print(f\"len(flat_verbs) = {len(flat_verbs)}\")\n",
    "print(\"Flat verbs:\")\n",
    "for verb in flat_verbs:\n",
    "    print(verb)\n",
    "\n",
    "flat_nouns = set()\n",
    "for noun in taxonomy_nouns:\n",
    "    flat_nouns.update(extract_words(noun))\n",
    "print(f\"len(flat_nouns) = {len(flat_nouns)}\")\n",
    "print(\"Flat nouns:\")\n",
    "for noun in flat_nouns:\n",
    "    print(noun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the verbs and nouns from EPIC-KITCHENS 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "\n",
    "def format_verb(verb: str) -> str:\n",
    "    return verb.replace(\"-\", \" \")\n",
    "\n",
    "\n",
    "def format_noun(noun: str) -> str:\n",
    "    if \":\" in noun:\n",
    "        return noun.split(\":\")[-1]\n",
    "    else:\n",
    "        return noun\n",
    "\n",
    "\n",
    "ek_verbs = set()\n",
    "ek_nouns = set()\n",
    "with open(\"../../../EPIC-KITCHENS/annotations/EPIC_100_validation.csv\") as f:\n",
    "    for row in csv.DictReader(f):\n",
    "        ek_verbs.add(format_verb(row[\"verb\"]))\n",
    "        ek_nouns.add(format_noun(row[\"noun\"]))\n",
    "\n",
    "print(f\"len(ek_verbs) = {len(ek_verbs)}\")\n",
    "print(\"EPIC-KITCHENS verbs:\")\n",
    "for verb in ek_verbs:\n",
    "    print(verb)\n",
    "\n",
    "print(f\"len(ek_nouns) = {len(ek_nouns)}\")\n",
    "print(\"EPIC-KITCHENS nouns:\")\n",
    "for noun in ek_nouns:\n",
    "    print(noun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare verbs and nouns from the two datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verb_intersection = flat_verbs.intersection(ek_verbs)\n",
    "noun_intersection = flat_nouns.intersection(ek_nouns)\n",
    "\n",
    "print(\"verb intersection\")\n",
    "for verb in verb_intersection:\n",
    "    print(verb)\n",
    "\n",
    "\n",
    "print()\n",
    "print(\"flat_verbs - ek_verbs\")\n",
    "for verb in flat_verbs - ek_verbs:\n",
    "    print(verb)\n",
    "\n",
    "print()\n",
    "print(\"ek_verbs - flat_verbs\")\n",
    "for verb in ek_verbs - flat_verbs:\n",
    "    print(verb)\n",
    "\n",
    "print()\n",
    "print(\"noun intersection\")\n",
    "for noun in noun_intersection:\n",
    "    print(noun)\n",
    "\n",
    "print()\n",
    "print(\"flat_nouns - ek_nouns\")\n",
    "for noun in flat_nouns - ek_nouns:\n",
    "    print(noun)\n",
    "\n",
    "print()\n",
    "print(\"ek_nouns - flat_nouns\")\n",
    "for noun in ek_nouns - flat_nouns:\n",
    "    print(noun)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "video-blip-IEa7WKva-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
